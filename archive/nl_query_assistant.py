import sys
import re
from query import execute_query
import pandas as pd
import json
import requests
import os
from dotenv import load_dotenv

# Carrega vari√°veis de ambiente
load_dotenv()

class DatabaseExplorer:
    """Explora e mapeia as tabelas e colunas dispon√≠veis no banco de dados"""
    
    def __init__(self):
        self.tables_cache = {}
        self.columns_cache = {}
    
    def get_available_tables(self):
        """Descobre tabelas dispon√≠veis no schema dw"""
        try:
            result = execute_query("SHOW TABLES FROM dw")
            tables = result['Table'].tolist() if 'Table' in result.columns else []
            return [f"dw.{table}" for table in tables]
        except Exception as e:
            print(f"Erro ao buscar tabelas: {e}")
            return ["dw.monetization_total"]  # fallback
    
    def get_table_columns(self, table_name):
        """Obt√©m colunas de uma tabela espec√≠fica"""
        if table_name in self.columns_cache:
            return self.columns_cache[table_name]
        
        try:
            result = execute_query(f"DESCRIBE {table_name}")
            columns = result['Column'].tolist() if 'Column' in result.columns else []
            self.columns_cache[table_name] = columns
            return columns
        except Exception as e:
            print(f"Erro ao buscar colunas de {table_name}: {e}")
            return []
    
    def find_relevant_columns(self, instruction, table_name):
        """Encontra colunas relevantes baseado na instru√ß√£o"""
        columns = self.get_table_columns(table_name)
        instruction_lower = instruction.lower()
        
        relevant_columns = []
        
        # Mapeamento de palavras-chave para poss√≠veis colunas
        keyword_mappings = {
            'pre√ßo': ['price', 'valor', 'amount', 'cost'],
            'price': ['price', 'valor', 'amount', 'cost'],
            'data': ['date', 'creation_date', 'year', 'month', 'day', 'dt'],
            'm√™s': ['month', 'mes'],
            'ano': ['year', 'ano'],
            'status': ['status', 'state', 'situation'],
            'usu√°rio': ['user_id', 'user', 'customer_id'],
            'categoria': ['category', 'categoria'],
            'produto': ['product', 'produto', 'item'],
            'receita': ['revenue', 'income', 'price', 'amount'],
            'vendas': ['sales', 'vendas', 'price', 'amount']
        }
        
        for word in instruction_lower.split():
            if word in keyword_mappings:
                for col in columns:
                    for mapping in keyword_mappings[word]:
                        if mapping.lower() in col.lower():
                            relevant_columns.append(col)
        
        return list(set(relevant_columns))

class AdvancedNLProcessor:
    """Processador avan√ßado de linguagem natural com detec√ß√£o de inten√ß√µes"""
    
    def __init__(self):
        self.intent_patterns = {
            'temporal_comparison': r'(compara|diferen√ßa|varia√ß√£o|evolu√ß√£o|tend√™ncia|vs|versus| e )',
            'aggregation': r'(total|soma|m√©dia|m√°ximo|m√≠nimo|quantidade|count)',
            'filtering': r'(onde|com|que|em|de|durante|entre)',
            'grouping': r'(por|agrupado|separado|dividido)',
            'ranking': r'(melhor|pior|maior|menor|top|primeiro|√∫ltimo)',
            'statistical': r'(desvio|distribui√ß√£o|estat√≠stica|an√°lise|padr√£o)'
        }
    
    def extract_intent(self, instruction):
        """Identifica m√∫ltiplas inten√ß√µes na instru√ß√£o"""
        intents = []
        for intent, pattern in self.intent_patterns.items():
            if re.search(pattern, instruction.lower()):
                intents.append(intent)
        return intents
    
    def detect_business_context(self, instruction):
        """Detecta contexto empresarial"""
        business_contexts = {
            'revenue': ['receita', 'faturamento', 'vendas', 'pre√ßo', 'price'],
            'customer': ['cliente', 'usu√°rio', 'comprador', 'user'],
            'product': ['produto', 'item', 'categoria', 'product'],
            'geography': ['regi√£o', 'estado', 'cidade', 'local', 'area'],
            'time_analysis': ['sazonal', 'mensal', 'trimestral', 'anual', 'per√≠odo']
        }
        
        detected = []
        for context, keywords in business_contexts.items():
            if any(kw in instruction.lower() for kw in keywords):
                detected.append(context)
        
        return detected

class InsightGenerator:
    """Gerador autom√°tico de insights dos dados"""
    
    def analyze_trends(self, data):
        """Identifica padr√µes e tend√™ncias automaticamente"""
        insights = []
        
        if len(data) < 2:
            return insights
        
        # An√°lise de crescimento
        if 'growth_percentage' in data.columns:
            growth = data['growth_percentage'].dropna()
            if not growth.empty:
                avg_growth = growth.mean()
                if avg_growth > 10:
                    insights.append(f"üìà Crescimento acelerado: {avg_growth:.1f}% em m√©dia")
                elif avg_growth > 2:
                    insights.append(f"üìä Crescimento moderado: {avg_growth:.1f}% em m√©dia")
                elif avg_growth < -10:
                    insights.append(f"üìâ Decl√≠nio acentuado: {avg_growth:.1f}% em m√©dia")
                elif avg_growth < -2:
                    insights.append(f"üìä Decl√≠nio moderado: {avg_growth:.1f}% em m√©dia")
                else:
                    insights.append(f"üìä Estabilidade: varia√ß√£o de {avg_growth:.1f}%")
        
        # An√°lise de valores
        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
        for col in numeric_cols:
            if any(keyword in col.lower() for keyword in ['avg_', 'sum_', 'price', 'amount']):
                values = data[col].dropna()
                if len(values) > 1:
                    std_dev = values.std()
                    mean_val = values.mean()
                    if std_dev / mean_val > 0.3:  # Alta variabilidade
                        insights.append(f"‚ö†Ô∏è Alta volatilidade nos dados ({col})")
        
        return insights
    
    def generate_data_visualization(self, data, instruction):
        """Cria visualiza√ß√£o textual dos dados"""
        if len(data) < 2:
            return ""
        
        # Encontra coluna de valores
        value_cols = [col for col in data.columns if any(prefix in col for prefix in ['avg_', 'sum_', 'count_', 'max_', 'min_'])]
        if not value_cols:
            return ""
        
        value_col = value_cols[0]
        values = data[value_col].tolist()
        
        if not values or all(pd.isna(values)):
            return ""
        
        max_val = max([v for v in values if not pd.isna(v)])
        min_val = min([v for v in values if not pd.isna(v)])
        
        chart_lines = []
        chart_lines.append("üìä Visualiza√ß√£o dos dados:")
        
        for i, val in enumerate(values):
            if pd.isna(val):
                continue
                
            # Calcula propor√ß√£o para a barra
            if max_val > min_val:
                proportion = (val - min_val) / (max_val - min_val)
            else:
                proportion = 1
            
            bar_length = max(1, int(proportion * 15))
            bar = "‚ñà" * bar_length + "‚ñë" * (15 - bar_length)
            
            # Tenta identificar o per√≠odo
            period = ""
            if 'year' in data.columns and 'month' in data.columns:
                year = data.iloc[i]['year']
                month = data.iloc[i]['month']
                month_names = ['', 'Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 
                              'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']
                period = f"{month_names[int(month)]}-{str(int(year))[2:]}"
            else:
                period = f"P{i+1}"
            
            chart_lines.append(f"  {period:>6}: {bar} {val:,.2f}")
        
        return "\n".join(chart_lines)

class SmartQueryBuilder:
    """Constr√≥i queries SQL inteligentes baseado em instru√ß√µes conversacionais"""
    
    def __init__(self, explorer):
        self.explorer = explorer
        self.month_mapping = {
            "jan": 1, "janeiro": 1, "fev": 2, "fevereiro": 2, "mar": 3, "mar√ßo": 3,
            "abr": 4, "abril": 4, "mai": 5, "maio": 5, "jun": 6, "junho": 6,
            "jul": 7, "julho": 7, "ago": 8, "agosto": 8, "set": 9, "setembro": 9,
            "out": 10, "outubro": 10, "nov": 11, "novembro": 11, "dez": 12, "dezembro": 12
        }
    
    def extract_date_filters(self, instruction, table_name):
        """Extrai filtros de data da instru√ß√£o usando nomes reais das colunas"""
        filters = []
        columns = self.explorer.get_table_columns(table_name)
        
        # Mapeia colunas de data dispon√≠veis
        date_columns = {}
        for col in columns:
            col_lower = col.lower()
            if any(date_keyword in col_lower for date_keyword in ['year', 'ano']):
                date_columns['year'] = col
            if any(date_keyword in col_lower for date_keyword in ['month', 'mes', 'm√™s']):
                date_columns['month'] = col
            if any(date_keyword in col_lower for date_keyword in ['day', 'dia']):
                date_columns['day'] = col
            if any(date_keyword in col_lower for date_keyword in ['date', 'data', 'creation', 'event']):
                date_columns['date'] = col
        
        # Padr√£o para m√∫ltiplos per√≠odos (ex: jan-24 e jan-25)
        date_pattern = r"(jan|janeiro|fev|fevereiro|mar|mar√ßo|abr|abril|mai|maio|jun|junho|jul|julho|ago|agosto|set|setembro|out|outubro|nov|novembro|dez|dezembro)[- ]?(\d{2,4})"
        matches = re.findall(date_pattern, instruction.lower())
        
        date_conditions = []
        for month_str, year_str in matches:
            month = self.month_mapping.get(month_str)
            year = int(year_str)
            if year < 100:
                year += 2000
            
            # Usa os nomes reais das colunas se dispon√≠veis
            if 'year' in date_columns and 'month' in date_columns:
                date_conditions.append(f"({date_columns['year']}={year} AND {date_columns['month']}={month})")
            elif 'date' in date_columns:
                # Se h√° uma coluna de data, tenta usar filtro por per√≠odo
                date_conditions.append(f"(EXTRACT(YEAR FROM {date_columns['date']})={year} AND EXTRACT(MONTH FROM {date_columns['date']})={month})")
        
        # Se h√° m√∫ltiplas condi√ß√µes de data, usa OR
        if len(date_conditions) > 1:
            filters.append(" OR ".join(date_conditions))
        elif len(date_conditions) == 1:
            filters.append(date_conditions[0])
        
        # Padr√£o para ano espec√≠fico
        year_pattern = r"\b(20\d{2})\b"
        year_matches = re.findall(year_pattern, instruction)
        for year in year_matches:
            if year not in [match[1] for match in matches]:  # Evita duplicatas
                if 'year' in date_columns:
                    filters.append(f"{date_columns['year']}={year}")
                elif 'date' in date_columns:
                    filters.append(f"EXTRACT(YEAR FROM {date_columns['date']})={year}")
        
        return filters
    
    def determine_operation(self, instruction):
        """Determina qual opera√ß√£o SQL realizar"""
        instruction_lower = instruction.lower()
        
        if any(word in instruction_lower for word in ["m√©dia", "media"]):
            return "AVG"
        elif any(word in instruction_lower for word in ["soma", "total", "somar"]):
            return "SUM"
        elif any(word in instruction_lower for word in ["contagem", "contar", "quantidade"]):
            return "COUNT"
        elif any(word in instruction_lower for word in ["m√°ximo", "maior", "max"]):
            return "MAX"
        elif any(word in instruction_lower for word in ["m√≠nimo", "menor", "min"]):
            return "MIN"
        elif any(word in instruction_lower for word in ["listar", "mostrar", "exibir"]):
            return "SELECT"
        else:
            return "SELECT"
    
    def build_query(self, instruction, table_name="dw.monetization_total"):
        """Constr√≥i uma query SQL baseada na instru√ß√£o"""
        operation = self.determine_operation(instruction)
        relevant_columns = self.explorer.find_relevant_columns(instruction, table_name)
        date_filters = self.extract_date_filters(instruction, table_name)
        
        # Detecta se √© uma compara√ß√£o/varia√ß√£o
        is_comparison = any(word in instruction.lower() for word in ["varia√ß√£o", "comparar", "diferen√ßa", "vs", "versus", " e "])
        
        # Determina a coluna principal para opera√ß√µes agregadas
        main_column = None
        if relevant_columns:
            # Prioriza colunas de pre√ßo/valor para opera√ß√µes num√©ricas
            price_cols = [col for col in relevant_columns if any(p in col.lower() for p in ['price', 'amount', 'valor'])]
            main_column = price_cols[0] if price_cols else relevant_columns[0]
        
        # Para compara√ß√µes com m√∫ltiplas datas, cria query mais complexa
        if is_comparison and len(date_filters) == 1 and " OR " in date_filters[0]:
            # Query para compara√ß√£o temporal
            if operation in ["AVG", "SUM", "MAX", "MIN"] and main_column:
                columns = self.explorer.get_table_columns(table_name)
                date_columns = {}
                for col in columns:
                    col_lower = col.lower()
                    if any(date_keyword in col_lower for date_keyword in ['year', 'ano']):
                        date_columns['year'] = col
                    if any(date_keyword in col_lower for date_keyword in ['month', 'mes', 'm√™s']):
                        date_columns['month'] = col
                    if any(date_keyword in col_lower for date_keyword in ['date', 'data', 'creation', 'event']):
                        date_columns['date'] = col
                
                if 'year' in date_columns and 'month' in date_columns:
                    select_part = f"SELECT {date_columns['year']}, {date_columns['month']}, {operation}({main_column}) AS {operation.lower()}_{main_column}"
                    query = f"{select_part} FROM {table_name} WHERE {date_filters[0]} GROUP BY {date_columns['year']}, {date_columns['month']} ORDER BY {date_columns['year']}, {date_columns['month']}"
                elif 'date' in date_columns:
                    select_part = f"SELECT EXTRACT(YEAR FROM {date_columns['date']}) as year, EXTRACT(MONTH FROM {date_columns['date']}) as month, {operation}({main_column}) AS {operation.lower()}_{main_column}"
                    query = f"{select_part} FROM {table_name} WHERE {date_filters[0]} GROUP BY EXTRACT(YEAR FROM {date_columns['date']}), EXTRACT(MONTH FROM {date_columns['date']}) ORDER BY year, month"
                else:
                    # Fallback para query simples
                    select_part = f"SELECT {operation}({main_column}) AS {operation.lower()}_{main_column}"
                    query = f"{select_part} FROM {table_name}"
                    if date_filters:
                        query += f" WHERE {date_filters[0]}"
            else:
                # Para outros tipos de opera√ß√£o
                select_part = f"SELECT {', '.join(relevant_columns[:5])}" if relevant_columns else "SELECT *"
                query = f"{select_part} FROM {table_name}"
                if date_filters:
                    query += f" WHERE {date_filters[0]}"
                query += " LIMIT 20"
        else:
            # Query normal
            if operation in ["AVG", "SUM", "MAX", "MIN"] and main_column:
                select_part = f"SELECT {operation}({main_column}) AS {operation.lower()}_{main_column}"
            elif operation == "COUNT":
                if "√∫nicos" in instruction.lower() or "distinct" in instruction.lower():
                    count_col = main_column or "*"
                    select_part = f"SELECT COUNT(DISTINCT {count_col}) AS unique_count"
                else:
                    select_part = "SELECT COUNT(*) AS total_count"
            else:
                # SELECT b√°sico
                if relevant_columns:
                    select_part = f"SELECT {', '.join(relevant_columns[:5])}"  # Limita a 5 colunas
                else:
                    select_part = "SELECT *"
            
            # Constr√≥i a query completa
            query = f"{select_part} FROM {table_name}"
            
            if date_filters:
                query += f" WHERE {' AND '.join(date_filters)}"
            
            # Adiciona LIMIT para queries SELECT b√°sicas
            if operation == "SELECT" and "LIMIT" not in query:
                query += " LIMIT 10"
        
        return query

class ToqanAIHelper:
    """Integra√ß√£o com API Toqan para interpreta√ß√£o inteligente de queries"""
    
    def __init__(self):
        self.api_key = os.getenv('TOQAN_API_KEY')
        self.base_url = 'https://api.coco.prod.toqan.ai/api'
    
    def enhanced_sql_help(self, instruction, table_schema, business_contexts, intents):
        """Vers√£o melhorada da consulta ao Toqan com contexto empresarial"""
        if not self.api_key:
            return None
        
        # Contexto mais rico para o Toqan
        context = f"""
        Voc√™ √© um analista de dados especialista em SQL e neg√≥cios de marketplace.
        
        CONTEXTO EMPRESARIAL: Marketplace OLX - dados de monetiza√ß√£o
        INTEN√á√ïES DETECTADAS: {', '.join(intents)}
        CONTEXTOS DE NEG√ìCIO: {', '.join(business_contexts)}
        
        SCHEMA DA TABELA: {table_schema}
        
        INSTRU√á√ÉO DO USU√ÅRIO: {instruction}
        
        Baseado no contexto, retorne um JSON estruturado:
        {{
            "sql_strategy": "estrat√©gia SQL recomendada",
            "business_insight": "insight de neg√≥cio a buscar",
            "recommended_metrics": ["m√©tricas complementares"],
            "grouping_suggestion": ["colunas para agrupar"],
            "filter_recommendations": ["filtros importantes"],
            "analysis_type": "comparativo|temporal|agregado|explorat√≥rio"
        }}
        """
        
        try:
            # Implementa√ß√£o similar √† vers√£o anterior, mas com contexto aprimorado
            create_payload = {"user_message": context}
            create_resp = requests.post(
                f"{self.base_url}/create_conversation",
                headers={"x-api-key": self.api_key},
                json=create_payload,
                timeout=10
            )
            
            if create_resp.status_code != 200:
                return None
            
            create_data = create_resp.json()
            conversation_id = create_data.get('conversation_id')
            request_id = create_data.get('request_id')
            
            if not conversation_id or not request_id:
                return None
            
            # Busca resposta com timeout menor para ser mais responsivo
            for _ in range(10):  # 10 segundos m√°ximo
                import time
                time.sleep(1)
                
                get_url = f"{self.base_url}/get_answer?conversation_id={conversation_id}&request_id={request_id}"
                ans_resp = requests.get(get_url, headers={"x-api-key": self.api_key}, timeout=5)
                
                if ans_resp.status_code == 200:
                    ans_data = ans_resp.json()
                    if ans_data.get('status') in ['completed', 'finished'] and ans_data.get('answer'):
                        answer = ans_data['answer']
                        try:
                            json_match = re.search(r'\{.*\}', answer, re.DOTALL)
                            if json_match:
                                return json.loads(json_match.group())
                        except:
                            pass
                        return {"explanation": answer}
            
            return None
            
        except Exception as e:
            print(f"‚ö†Ô∏è Toqan temporariamente indispon√≠vel: {e}")
            return None

class AdaptiveQueryBuilder(SmartQueryBuilder):
    """Construtor de queries adaptativo com fallbacks e an√°lises avan√ßadas"""
    
    def __init__(self, explorer):
        super().__init__(explorer)
        self.nl_processor = AdvancedNLProcessor()
        self.insight_generator = InsightGenerator()
    
    def generate_statistical_query(self, instruction, table_name, intents):
        """Gera query com an√°lises estat√≠sticas autom√°ticas"""
        relevant_columns = self.explorer.find_relevant_columns(instruction, table_name)
        date_filters = self.extract_date_filters(instruction, table_name)
        
        # Encontra coluna principal de valor
        main_column = None
        if relevant_columns:
            price_cols = [col for col in relevant_columns if any(p in col.lower() for p in ['price', 'amount', 'valor'])]
            main_column = price_cols[0] if price_cols else relevant_columns[0]
        
        if not main_column:
            return None
        
        # Detecta colunas de data para agrupamento temporal
        columns = self.explorer.get_table_columns(table_name)
        date_columns = {}
        for col in columns:
            col_lower = col.lower()
            if any(date_keyword in col_lower for date_keyword in ['year', 'ano']):
                date_columns['year'] = col
            if any(date_keyword in col_lower for date_keyword in ['month', 'mes', 'm√™s']):
                date_columns['month'] = col
            if any(date_keyword in col_lower for date_keyword in ['date', 'data', 'creation', 'event']):
                date_columns['date'] = col
        
        # Query com an√°lises estat√≠sticas avan√ßadas
        if 'temporal_comparison' in intents and date_columns:
            if 'year' in date_columns and 'month' in date_columns:
                query = f"""
                WITH monthly_stats AS (
                    SELECT 
                        {date_columns['year']} as year,
                        {date_columns['month']} as month,
                        AVG({main_column}) as avg_{main_column},
                        COUNT(*) as record_count,
                        STDDEV({main_column}) as stddev_{main_column},
                        MIN({main_column}) as min_{main_column},
                        MAX({main_column}) as max_{main_column}
                    FROM {table_name}
                    {f'WHERE {date_filters[0]}' if date_filters else ''}
                    GROUP BY {date_columns['year']}, {date_columns['month']}
                ),
                growth_analysis AS (
                    SELECT *,
                        LAG(avg_{main_column}) OVER (ORDER BY year, month) as prev_avg,
                        avg_{main_column} - LAG(avg_{main_column}) OVER (ORDER BY year, month) as absolute_change
                    FROM monthly_stats
                )
                SELECT *,
                    CASE 
                        WHEN prev_avg > 0 AND prev_avg IS NOT NULL 
                        THEN (absolute_change / prev_avg) * 100 
                        ELSE NULL 
                    END as growth_percentage
                FROM growth_analysis
                ORDER BY year, month
                """
            elif 'date' in date_columns:
                query = f"""
                WITH monthly_stats AS (
                    SELECT 
                        EXTRACT(YEAR FROM {date_columns['date']}) as year,
                        EXTRACT(MONTH FROM {date_columns['date']}) as month,
                        AVG({main_column}) as avg_{main_column},
                        COUNT(*) as record_count,
                        STDDEV({main_column}) as stddev_{main_column}
                    FROM {table_name}
                    {f'WHERE {date_filters[0]}' if date_filters else ''}
                    GROUP BY EXTRACT(YEAR FROM {date_columns['date']}), EXTRACT(MONTH FROM {date_columns['date']})
                ),
                growth_analysis AS (
                    SELECT *,
                        LAG(avg_{main_column}) OVER (ORDER BY year, month) as prev_avg,
                        avg_{main_column} - LAG(avg_{main_column}) OVER (ORDER BY year, month) as absolute_change
                    FROM monthly_stats
                )
                SELECT *,
                    CASE 
                        WHEN prev_avg > 0 AND prev_avg IS NOT NULL 
                        THEN (absolute_change / prev_avg) * 100 
                        ELSE NULL 
                    END as growth_percentage
                FROM growth_analysis
                ORDER BY year, month
                """
            else:
                return None
        else:
            # Query estat√≠stica simples
            operation = self.determine_operation(instruction)
            query = f"SELECT {operation}({main_column}) AS {operation.lower()}_{main_column} FROM {table_name}"
            if date_filters:
                query += f" WHERE {' AND '.join(date_filters)}"
        
        return query
    
    def build_adaptive_queries(self, instruction, table_name="dw.monetization_total"):
        """Gera m√∫ltiplas vers√µes de query com fallbacks"""
        intents = self.nl_processor.extract_intent(instruction)
        business_contexts = self.nl_processor.detect_business_context(instruction)
        
        queries = []
        
        # Query 1: Estat√≠stica avan√ßada (se aplic√°vel)
        if 'temporal_comparison' in intents or 'statistical' in intents:
            advanced_query = self.generate_statistical_query(instruction, table_name, intents)
            if advanced_query:
                queries.append(('advanced_statistical', advanced_query))
        
        # Query 2: Compara√ß√£o temporal (query atual melhorada)
        comparison_query = self.build_query(instruction, table_name)
        queries.append(('temporal_comparison', comparison_query))
        
        # Query 3: Agrega√ß√£o simples (fallback)
        operation = self.determine_operation(instruction)
        relevant_columns = self.explorer.find_relevant_columns(instruction, table_name)
        if relevant_columns:
            main_column = relevant_columns[0]
            simple_query = f"SELECT {operation}({main_column}) AS {operation.lower()}_{main_column} FROM {table_name}"
            date_filters = self.extract_date_filters(instruction, table_name)
            if date_filters:
                # Para fallback, usa apenas o primeiro filtro de data
                first_filter = date_filters[0].split(' OR ')[0] if ' OR ' in date_filters[0] else date_filters[0]
                simple_query += f" WHERE {first_filter}"
            queries.append(('simple_aggregation', simple_query))
        
        # Query 4: Explorat√≥ria (√∫ltimo fallback)
        explore_query = f"SELECT * FROM {table_name} LIMIT 5"
        queries.append(('exploration', explore_query))
        
        return queries, intents, business_contexts
    """Processador avan√ßado de linguagem natural com detec√ß√£o de inten√ß√µes"""
    
    def __init__(self):
        self.intent_patterns = {
            'temporal_comparison': r'(compara|diferen√ßa|varia√ß√£o|evolu√ß√£o|tend√™ncia|vs|versus| e )',
            'aggregation': r'(total|soma|m√©dia|m√°ximo|m√≠nimo|quantidade|count)',
            'filtering': r'(onde|com|que|em|de|durante|entre)',
            'grouping': r'(por|agrupado|separado|dividido)',
            'ranking': r'(melhor|pior|maior|menor|top|primeiro|√∫ltimo)',
            'statistical': r'(desvio|distribui√ß√£o|estat√≠stica|an√°lise|padr√£o)'
        }
    
    def extract_intent(self, instruction):
        """Identifica m√∫ltiplas inten√ß√µes na instru√ß√£o"""
        intents = []
        for intent, pattern in self.intent_patterns.items():
            if re.search(pattern, instruction.lower()):
                intents.append(intent)
        return intents
    
    def detect_business_context(self, instruction):
        """Detecta contexto empresarial"""
        business_contexts = {
            'revenue': ['receita', 'faturamento', 'vendas', 'pre√ßo', 'price'],
            'customer': ['cliente', 'usu√°rio', 'comprador', 'user'],
            'product': ['produto', 'item', 'categoria', 'product'],
            'geography': ['regi√£o', 'estado', 'cidade', 'local', 'area'],
            'time_analysis': ['sazonal', 'mensal', 'trimestral', 'anual', 'per√≠odo']
        }
        
        detected = []
        for context, keywords in business_contexts.items():
            if any(kw in instruction.lower() for kw in keywords):
                detected.append(context)
        
        return detected

class InsightGenerator:
    """Gerador autom√°tico de insights dos dados"""
    
    def analyze_trends(self, data):
        """Identifica padr√µes e tend√™ncias automaticamente"""
        insights = []
        
        if len(data) < 2:
            return insights
        
        # An√°lise de crescimento
        if 'growth_percentage' in data.columns:
            growth = data['growth_percentage'].dropna()
            if not growth.empty:
                avg_growth = growth.mean()
                if avg_growth > 10:
                    insights.append(f"üìà Crescimento acelerado: {avg_growth:.1f}% em m√©dia")
                elif avg_growth > 2:
                    insights.append(f"üìä Crescimento moderado: {avg_growth:.1f}% em m√©dia")
                elif avg_growth < -10:
                    insights.append(f"üìâ Decl√≠nio acentuado: {avg_growth:.1f}% em m√©dia")
                elif avg_growth < -2:
                    insights.append(f"üìä Decl√≠nio moderado: {avg_growth:.1f}% em m√©dia")
                else:
                    insights.append(f"üìä Estabilidade: varia√ß√£o de {avg_growth:.1f}%")
        
        # An√°lise de valores
        numeric_cols = data.select_dtypes(include=['float64', 'int64']).columns
        for col in numeric_cols:
            if any(keyword in col.lower() for keyword in ['avg_', 'sum_', 'price', 'amount']):
                values = data[col].dropna()
                if len(values) > 1:
                    std_dev = values.std()
                    mean_val = values.mean()
                    if std_dev / mean_val > 0.3:  # Alta variabilidade
                        insights.append(f"‚ö†Ô∏è Alta volatilidade nos dados ({col})")
        
        return insights
    
    def generate_data_visualization(self, data, instruction):
        """Cria visualiza√ß√£o textual dos dados"""
        if len(data) < 2:
            return ""
        
        # Encontra coluna de valores
        value_cols = [col for col in data.columns if any(prefix in col for prefix in ['avg_', 'sum_', 'count_', 'max_', 'min_'])]
        if not value_cols:
            return ""
        
        value_col = value_cols[0]
        values = data[value_col].tolist()
        
        if not values or all(pd.isna(values)):
            return ""
        
        max_val = max([v for v in values if not pd.isna(v)])
        min_val = min([v for v in values if not pd.isna(v)])
        
        chart_lines = []
        chart_lines.append("üìä Visualiza√ß√£o dos dados:")
        
        for i, val in enumerate(values):
            if pd.isna(val):
                continue
                
            # Calcula propor√ß√£o para a barra
            if max_val > min_val:
                proportion = (val - min_val) / (max_val - min_val)
            else:
                proportion = 1
            
            bar_length = max(1, int(proportion * 15))
            bar = "‚ñà" * bar_length + "‚ñë" * (15 - bar_length)
            
            # Tenta identificar o per√≠odo
            period = ""
            if 'year' in data.columns and 'month' in data.columns:
                year = data.iloc[i]['year']
                month = data.iloc[i]['month']
                month_names = ['', 'Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 
                              'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']
                period = f"{month_names[int(month)]}-{str(int(year))[2:]}"
            else:
                period = f"P{i+1}"
            
            chart_lines.append(f"  {period:>6}: {bar} {val:,.2f}")
        
        return "\n".join(chart_lines)
    """Integra√ß√£o com API Toqan para interpreta√ß√£o inteligente de queries"""
    
    def __init__(self):
        self.api_key = os.getenv('TOQAN_API_KEY')
        self.base_url = 'https://api.coco.prod.toqan.ai/api'
    
    def ask_toqan_for_sql_help(self, instruction, table_schema):
        """Usa Toqan para ajudar na convers√£o NL‚ÜíSQL"""
        if not self.api_key:
            return None
        
        # Prepara contexto para o Toqan
        context = f"""
        Voc√™ √© um especialista em SQL. Baseado na instru√ß√£o em portugu√™s e no schema da tabela abaixo, 
        me ajude a entender:
        1. Que tipo de opera√ß√£o SQL √© necess√°ria (SELECT, AVG, SUM, COUNT, etc.)
        2. Quais colunas s√£o relevantes
        3. Que filtros aplicar
        
        SCHEMA DA TABELA: {table_schema}
        
        INSTRU√á√ÉO: {instruction}
        
        Responda apenas com um JSON no formato:
        {{
            "operation": "AVG|SUM|COUNT|SELECT|MAX|MIN",
            "columns": ["lista", "de", "colunas"],
            "filters": ["lista de condi√ß√µes WHERE"],
            "explanation": "breve explica√ß√£o"
        }}
        """
        
        try:
            # Cria conversa
            create_payload = {"user_message": context}
            create_resp = requests.post(
                f"{self.base_url}/create_conversation",
                headers={"x-api-key": self.api_key},
                json=create_payload,
                timeout=10
            )
            
            if create_resp.status_code != 200:
                return None
            
            create_data = create_resp.json()
            conversation_id = create_data.get('conversation_id')
            request_id = create_data.get('request_id')
            
            if not conversation_id or not request_id:
                return None
            
            # Busca resposta
            for _ in range(15):  # Tenta por 15 segundos
                import time
                time.sleep(1)
                
                get_url = f"{self.base_url}/get_answer?conversation_id={conversation_id}&request_id={request_id}"
                ans_resp = requests.get(get_url, headers={"x-api-key": self.api_key}, timeout=5)
                
                if ans_resp.status_code == 200:
                    ans_data = ans_resp.json()
                    if ans_data.get('status') in ['completed', 'finished'] and ans_data.get('answer'):
                        # Tenta extrair JSON da resposta
                        answer = ans_data['answer']
                        try:
                            # Procura por JSON na resposta
                            import re
                            json_match = re.search(r'\{.*\}', answer, re.DOTALL)
                            if json_match:
                                return json.loads(json_match.group())
                        except:
                            pass
                        return {"explanation": answer}  # Fallback
            
            return None
            
        except Exception as e:
            print(f"Erro ao consultar Toqan: {e}")
            return None

def nl_to_sql_adaptive(instruction):
    """Fun√ß√£o principal melhorada com queries adaptativas"""
    explorer = DatabaseExplorer()
    builder = AdaptiveQueryBuilder(explorer)
    toqan = ToqanAIHelper()
    
    # Descobre tabela principal
    tables = explorer.get_available_tables()
    main_table = "dw.monetization_total"
    
    for table in tables:
        table_name = table.split('.')[-1]
        if table_name.lower() in instruction.lower():
            main_table = table
            break
    
    # Gera queries adaptativas
    queries, intents, business_contexts = builder.build_adaptive_queries(instruction, main_table)
    
    # Consulta Toqan se dispon√≠vel
    table_columns = explorer.get_table_columns(main_table)
    toqan_help = toqan.enhanced_sql_help(instruction, table_columns, business_contexts, intents)
    
    if toqan_help and 'business_insight' in toqan_help:
        print(f"ü§ñ Toqan sugere: {toqan_help.get('business_insight', 'An√°lise inteligente')}")
    
    return queries

def execute_with_adaptive_fallback(queries):
    """Executa queries com fallback autom√°tico e an√°lise de resultados"""
    insight_gen = InsightGenerator()
    
    for query_type, query in queries:
        try:
            print(f"üîÑ Tentando estrat√©gia: {query_type}")
            result = execute_query(query)
            
            if not result.empty:
                print(f"‚úÖ Sucesso com estrat√©gia: {query_type}")
                
                # Gera insights autom√°ticos
                insights = insight_gen.analyze_trends(result)
                visualization = insight_gen.generate_data_visualization(result, "")
                
                return result, query_type, query, insights, visualization
                
        except Exception as e:
            print(f"‚ùå Estrat√©gia {query_type} falhou: {str(e)[:100]}...")
            continue
    
    return None, None, None, [], ""

def generate_natural_response(result_df, instruction, sql_query):
    """Gera uma resposta em linguagem natural baseada no resultado"""
    if result_df.empty:
        return "N√£o foram encontrados dados para sua consulta."
    
    instruction_lower = instruction.lower()
    columns = result_df.columns.tolist()
    
    # Detecta se √© uma compara√ß√£o temporal
    is_comparison = any(word in instruction_lower for word in ["varia√ß√£o", "comparar", "diferen√ßa", "vs", "versus", " e "])
    
    if is_comparison and len(result_df) > 1:
        # Resposta para compara√ß√µes temporais
        if any('avg_' in col for col in columns):
            avg_col = [col for col in columns if 'avg_' in col][0]
            
            response_parts = []
            for _, row in result_df.iterrows():
                if 'year' in columns and 'month' in columns:
                    year, month = row['year'], row['month']
                    value = row[avg_col]
                    month_name = list(SmartQueryBuilder({}).month_mapping.keys())[month-1]
                    response_parts.append(f"{month_name}-{str(year)[2:]}: {value:,.2f}")
            
            # Calcula varia√ß√£o se h√° 2 per√≠odos
            if len(result_df) == 2:
                values = result_df[avg_col].tolist()
                variation = ((values[1] - values[0]) / values[0]) * 100
                variation_text = f"aumento de {variation:.1f}%" if variation > 0 else f"redu√ß√£o de {abs(variation):.1f}%"
                return f"M√©dias: {', '.join(response_parts)}. Varia√ß√£o: {variation_text}."
            else:
                return f"M√©dias por per√≠odo: {', '.join(response_parts)}."
    
    # Respostas para opera√ß√µes simples
    if any('avg_' in col for col in columns):
        avg_col = [col for col in columns if 'avg_' in col][0]
        value = result_df[avg_col].iloc[0]
        if pd.isna(value):
            return "N√£o h√° dados suficientes para calcular a m√©dia solicitada."
        return f"A m√©dia √© {value:,.2f}."
    
    elif any('sum_' in col for col in columns):
        sum_col = [col for col in columns if 'sum_' in col][0]
        value = result_df[sum_col].iloc[0]
        if pd.isna(value):
            return "N√£o h√° dados para somar."
        return f"A soma total √© {value:,.2f}."
    
    elif any('max_' in col for col in columns):
        max_col = [col for col in columns if 'max_' in col][0]
        value = result_df[max_col].iloc[0]
        return f"O valor m√°ximo √© {value:,.2f}."
    
    elif any('min_' in col for col in columns):
        min_col = [col for col in columns if 'min_' in col][0]
        value = result_df[min_col].iloc[0]
        return f"O valor m√≠nimo √© {value:,.2f}."
    
    elif 'unique_count' in columns:
        count = result_df['unique_count'].iloc[0]
        return f"Existem {count} valores √∫nicos."
    
    elif 'total_count' in columns:
        count = result_df['total_count'].iloc[0]
        return f"Total de {count} registros encontrados."
    
    else:
        # Para resultados tabulares, fornece um resumo
        rows = len(result_df)
        cols = len(result_df.columns)
        
        if rows == 1:
            return f"Encontrado 1 registro com {cols} campos."
        else:
            return f"Encontrados {rows} registros com {cols} campos cada."

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Uso: python nl_query_assistant.py 'sua pergunta em linguagem natural'")
        print("Exemplos:")
        print("  'Qual a m√©dia do pre√ßo em jan-24?'")
        print("  'Quantos usu√°rios √∫nicos temos?'")
        print("  'Soma das vendas de 2023'")
        print("  'Listar os produtos mais caros'")
        sys.exit(1)
    
    instruction = " ".join(sys.argv[1:])
    
    print(f"ü§ñ Processando: {instruction}")
    print("=" * 50)
    
    try:
        # Gera queries adaptativas
        queries = nl_to_sql_adaptive(instruction)
        
        if not queries:
            print("‚ùå N√£o foi poss√≠vel interpretar sua solicita√ß√£o.")
            print("Tente ser mais espec√≠fico ou usar palavras-chave como: m√©dia, soma, quantidade, etc.")
            sys.exit(1)
        
        print(f"üéØ Geradas {len(queries)} estrat√©gias de consulta")
        print()
        
        # Executa com fallback adaptativo
        result_df, strategy_used, sql_query, insights, visualization = execute_with_adaptive_fallback(queries)
        
        if result_df is None:
            print("‚ùå Todas as estrat√©gias de consulta falharam.")
            print("Verifique a conectividade com o banco de dados ou reformule a pergunta.")
            sys.exit(1)
        
        print(f"üìù Query SQL executada ({strategy_used}):")
        print(f"   {sql_query}")
        print()
        
        # Mostra visualiza√ß√£o se dispon√≠vel
        if visualization:
            print(visualization)
            print()
        
        # Mostra o resultado tabular
        print("üìä Resultado da consulta:")
        print(result_df.to_string(index=False))
        print()
        
        # Gera resposta em linguagem natural
        natural_response = generate_natural_response(result_df, instruction, sql_query)
        print(f"üí¨ Resposta: {natural_response}")
        
        # Mostra insights autom√°ticos
        if insights:
            print("\nüîç Insights autom√°ticos:")
            for insight in insights:
                print(f"   ‚Ä¢ {insight}")
        
    except Exception as e:
        print(f"‚ùå Erro ao executar a consulta: {e}")
        print("\nPoss√≠veis causas:")
        print("- Problema de conex√£o com o banco de dados")
        print("- Tabela ou coluna n√£o existe")
        print("- Sintaxe SQL incorreta")
